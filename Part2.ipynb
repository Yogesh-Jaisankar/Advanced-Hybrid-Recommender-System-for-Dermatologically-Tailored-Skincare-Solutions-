{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8478d4-cfa8-41b2-b3ed-9ead4e1cf5f4",
   "metadata": {},
   "source": [
    "## Colloborative filtering using Neural Collaborative Filtering [NCF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206bf606-1548-497b-8a20-2260ebad5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your datasets\n",
    "reviews_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/Reviews/combined_file.csv', dtype=str)\n",
    "product_info_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/product_info.csv', dtype=str)\n",
    "\n",
    "# Clean and preprocess data\n",
    "reviews_data['rating'] = reviews_data['rating'].astype(float)\n",
    "reviews_data = reviews_data[['author_id', 'product_id', 'rating']]\n",
    "\n",
    "# Encode user IDs and product IDs\n",
    "user_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()\n",
    "\n",
    "reviews_data['user'] = user_encoder.fit_transform(reviews_data['author_id'])\n",
    "reviews_data['product'] = product_encoder.fit_transform(reviews_data['product_id'])\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_data, test_data = train_test_split(reviews_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare user-product interaction matrix\n",
    "num_users = reviews_data['user'].nunique()\n",
    "num_products = reviews_data['product'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0259d46-acf7-4f99-a0b1-2fb737eab317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_ncf_model(num_users, num_products):\n",
    "    user_input = layers.Input(shape=(1,), name='user_input')\n",
    "    product_input = layers.Input(shape=(1,), name='product_input')\n",
    "    \n",
    "    # Embedding layers\n",
    "    user_embedding = layers.Embedding(input_dim=num_users, output_dim=16)(user_input)\n",
    "    product_embedding = layers.Embedding(input_dim=num_products, output_dim=16)(product_input)\n",
    "\n",
    "    # Flatten the embeddings\n",
    "    user_vecs = layers.Flatten()(user_embedding)\n",
    "    product_vecs = layers.Flatten()(product_embedding)\n",
    "\n",
    "    # Concatenate the two embeddings\n",
    "    concat = layers.Concatenate()([user_vecs, product_vecs])\n",
    "\n",
    "    # Dense layers\n",
    "    dense = layers.Dense(64, activation='relu')(concat)\n",
    "    dense = layers.Dense(32, activation='relu')(dense)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Dense(1)(dense)\n",
    "\n",
    "    model = models.Model(inputs=[user_input, product_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "ncf_model = create_ncf_model(num_users, num_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8883e839-970d-4a8f-8236-5ac8eb340876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m38126/38126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3650690d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "X_train = [train_data['user'].values, train_data['product'].values]\n",
    "y_train = train_data['rating'].values\n",
    "\n",
    "ncf_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66f2ee0-f0ab-4c3a-a10a-7613f29349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, model, num_recommendations=5):\n",
    "    user_idx = user_encoder.transform([user_id])[0]\n",
    "    product_indices = range(num_products)\n",
    "\n",
    "    # Create input for prediction\n",
    "    user_input = tf.constant([user_idx] * num_products)\n",
    "    product_input = tf.constant(product_indices)\n",
    "\n",
    "    # Predict ratings\n",
    "    predicted_ratings = model.predict([user_input, product_input])\n",
    "\n",
    "    # Get the top N recommendations\n",
    "    recommended_product_indices = predicted_ratings.flatten().argsort()[-num_recommendations:][::-1]\n",
    "    recommended_products = product_encoder.inverse_transform(recommended_product_indices)\n",
    "    \n",
    "    return recommended_products\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973924d1-78b4-4620-9df6-fa7e307a5cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "Recommended products for user: [nan 'P443358' 'P443830' 'P443829' 'P443812']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_id = '2190293206'  # replace with a valid author_id\n",
    "recommendations = get_recommendations(user_id, ncf_model)\n",
    "print(\"Recommended products for user:\", recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39a2f50e-aa8b-48fb-a670-954a3e8f8432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21182/21182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225us/step\n",
      "Accuracy: 0.3433\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34331522557001093, 1.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate model performance on test data\n",
    "def evaluate_model(model, test_data, threshold=3):\n",
    "    # Get test user and product inputs\n",
    "    X_test = [test_data['user'].values, test_data['product'].values]\n",
    "    \n",
    "    # Get actual ratings\n",
    "    y_true = test_data['rating'].values\n",
    "    \n",
    "    # Get model predictions\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    \n",
    "    # Apply threshold to predictions and true labels (converting to binary labels)\n",
    "    y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "    y_true_binary = np.where(y_true >= threshold, 1, 0)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, zero_division=1)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, zero_division=1)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, zero_division=1)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluate_model(ncf_model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c584bf8-afe1-4546-8cdd-5e5d04a0c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e861916-6f80-42a6-b954-c054014496c9",
   "metadata": {},
   "source": [
    "## Colloborative filtering using [Neutralised matrix factorisation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e25362-e90b-4673-b612-fe4bdf7cc2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/nx2__31n62781txpbf95sg7m0000gn/T/ipykernel_10527/2788908821.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['rating'] = pd.to_numeric(data['rating'])\n",
      "/var/folders/wv/nx2__31n62781txpbf95sg7m0000gn/T/ipykernel_10527/2788908821.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_id'] = user_encoder.fit_transform(data['author_id'])\n",
      "/var/folders/wv/nx2__31n62781txpbf95sg7m0000gn/T/ipykernel_10527/2788908821.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['product_id'] = product_encoder.fit_transform(data['product_id'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load datasets\n",
    "reviews_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/Reviews/combined_file.csv', dtype=str)\n",
    "product_info_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/product_info.csv', dtype=str)\n",
    "\n",
    "# Extract relevant columns\n",
    "data = reviews_data[['author_id', 'product_id', 'rating']]\n",
    "\n",
    "# Convert rating to numeric\n",
    "data['rating'] = pd.to_numeric(data['rating'])\n",
    "\n",
    "# Encode user IDs and product IDs\n",
    "user_encoder = LabelEncoder()\n",
    "data['user_id'] = user_encoder.fit_transform(data['author_id'])\n",
    "\n",
    "product_encoder = LabelEncoder()\n",
    "data['product_id'] = product_encoder.fit_transform(data['product_id'])\n",
    "\n",
    "# Create a final dataset with user_id, product_id, and rating\n",
    "final_data = data[['user_id', 'product_id', 'rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d47397-4767-468d-9879-3b96aa96b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(final_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f72d29c-57e4-4374-a01c-8b0b18b75b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Get number of users and products\n",
    "num_users = data['user_id'].nunique()\n",
    "num_products = data['product_id'].nunique()\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_size = 8\n",
    "\n",
    "# Define the NeuMF model\n",
    "def create_neumf_model(num_users, num_products, embedding_size):\n",
    "    # Input layers\n",
    "    user_input = layers.Input(shape=(1,), name='user_input')\n",
    "    product_input = layers.Input(shape=(1,), name='product_input')\n",
    "    \n",
    "    # User and product embeddings\n",
    "    user_embedding = layers.Embedding(input_dim=num_users, output_dim=embedding_size)(user_input)\n",
    "    product_embedding = layers.Embedding(input_dim=num_products, output_dim=embedding_size)(product_input)\n",
    "    \n",
    "    # Flatten the embeddings\n",
    "    user_vecs = layers.Flatten()(user_embedding)\n",
    "    product_vecs = layers.Flatten()(product_embedding)\n",
    "    \n",
    "    # Concatenate the vectors\n",
    "    merged_vecs = layers.Concatenate()([user_vecs, product_vecs])\n",
    "    \n",
    "    # MLP layers\n",
    "    x = layers.Dense(128, activation='relu')(merged_vecs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Dense(1)(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=[user_input, product_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "neumf_model = create_neumf_model(num_users, num_products, embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc8e77b-e3cb-49cc-9b60-f3a6e406ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_train = [train_data['user_id'].values, train_data['product_id'].values]\n",
    "y_train = train_data['rating'].values\n",
    "\n",
    "# Prepare test data\n",
    "X_test = [test_data['user_id'].values, test_data['product_id'].values]\n",
    "y_test = test_data['rating'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aa06cb-3dad-44e2-a512-3f2075797979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21182/21182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x38bead4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "neumf_model.fit(X_train, y_train, epochs=1, batch_size=128, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d66d1a-95b8-499f-87ed-2e08e12e2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step\n",
      "Recommendations for User ID 0:\n",
      "- Product ID: P443842\n",
      "- Product ID: P448802\n",
      "- Product ID: P479841\n",
      "- Product ID: P500757\n",
      "- Product ID: P418624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your trained NeuMF model as `neumf_model`\n",
    "# And your dataset has been encoded with user_ids and product_ids\n",
    "\n",
    "# Define the specific user ID for whom you want recommendations\n",
    "specific_user_id = 0  # Replace with the actual user ID you want to check\n",
    "\n",
    "# Get all product IDs (assuming they are encoded)\n",
    "product_ids = final_data['product_id'].unique()\n",
    "\n",
    "# Create user-product pairs for the specific user\n",
    "user_product_pairs = np.array([[specific_user_id, product_id] for product_id in product_ids])\n",
    "\n",
    "# Predict ratings for the user-product pairs\n",
    "predicted_ratings = neumf_model.predict([user_product_pairs[:, 0], user_product_pairs[:, 1]])\n",
    "\n",
    "# Create a DataFrame for the predicted ratings\n",
    "user_recommendations_df = pd.DataFrame(predicted_ratings, columns=['predicted_rating'])\n",
    "user_recommendations_df['user_id'] = specific_user_id\n",
    "user_recommendations_df['product_id'] = user_product_pairs[:, 1]\n",
    "\n",
    "# Get the top N recommendations for the specific user\n",
    "top_n = 5  # Specify the number of recommendations\n",
    "top_recommendations = user_recommendations_df.nlargest(top_n, 'predicted_rating')\n",
    "\n",
    "# If you want to map back to original product IDs (if encoded)\n",
    "top_recommendations['product_id'] = product_encoder.inverse_transform(top_recommendations['product_id'].astype(int))\n",
    "\n",
    "# Display recommendations for the specific user\n",
    "print(f\"Recommendations for User ID {specific_user_id}:\")\n",
    "if top_recommendations.empty:\n",
    "    print(\"No recommendations found.\")\n",
    "else:\n",
    "    for _, row in top_recommendations.iterrows():\n",
    "        print(f\"- Product ID: {row['product_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7aedcf-04b7-4386-ae30-2c0a722f7357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "Recommendations for User ID 0:\n",
      "- Product ID: P443842 with predicted rating: nan\n",
      "- Product ID: P448802 with predicted rating: nan\n",
      "- Product ID: P479841 with predicted rating: nan\n",
      "- Product ID: P500757 with predicted rating: nan\n",
      "- Product ID: P418624 with predicted rating: nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your trained NeuMF model as `neumf_model`\n",
    "# And your dataset has been encoded with user_ids and product_ids\n",
    "\n",
    "# Define the specific user ID for whom you want recommendations\n",
    "specific_user_id = 0  # Replace with the actual user ID you want to check\n",
    "\n",
    "# Get all product IDs (assuming they are encoded)\n",
    "product_ids = final_data['product_id'].unique()\n",
    "\n",
    "# Create user-product pairs for the specific user\n",
    "user_product_pairs = np.array([[specific_user_id, product_id] for product_id in product_ids])\n",
    "\n",
    "# Predict ratings for the user-product pairs\n",
    "predicted_ratings = neumf_model.predict([user_product_pairs[:, 0], user_product_pairs[:, 1]])\n",
    "\n",
    "# Create a DataFrame for the predicted ratings\n",
    "user_recommendations_df = pd.DataFrame(predicted_ratings, columns=['predicted_rating'])\n",
    "user_recommendations_df['user_id'] = specific_user_id\n",
    "user_recommendations_df['product_id'] = user_product_pairs[:, 1]\n",
    "\n",
    "# Get the top N recommendations for the specific user\n",
    "top_n = 5  # Specify the number of recommendations\n",
    "top_recommendations = user_recommendations_df.nlargest(top_n, 'predicted_rating')\n",
    "\n",
    "# If you want to map back to original product IDs (if encoded)\n",
    "top_recommendations['product_id'] = product_encoder.inverse_transform(top_recommendations['product_id'].astype(int))\n",
    "\n",
    "# Display recommendations for the specific user\n",
    "print(f\"Recommendations for User ID {specific_user_id}:\")\n",
    "if top_recommendations.empty:\n",
    "    print(\"No recommendations found.\")\n",
    "else:\n",
    "    for _, row in top_recommendations.iterrows():\n",
    "        print(f\"- Product ID: {row['product_id']} with predicted rating: {row['predicted_rating']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71cb86d5-ca4a-4daa-8315-f86a913de7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have your trained NeuMF model as `neumf_model`\n",
    "# And your dataset has been encoded with user_ids and product_ids\n",
    "\n",
    "# Define the specific user ID for whom you want recommendations\n",
    "specific_user_id = 10  # Replace with the actual user ID you want to check\n",
    "\n",
    "# Get all product IDs (assuming they are encoded)\n",
    "product_ids = final_data['product_id'].unique()\n",
    "\n",
    "# Create user-product pairs for the specific user\n",
    "user_product_pairs = np.array([[specific_user_id, product_id] for product_id in product_ids])\n",
    "\n",
    "# Predict ratings for the user-product pairs\n",
    "predicted_ratings = neumf_model.predict([user_product_pairs[:, 0], user_product_pairs[:, 1]])\n",
    "\n",
    "# Create a DataFrame for the predicted ratings\n",
    "user_recommendations_df = pd.DataFrame(predicted_ratings, columns=['predicted_rating'])\n",
    "user_recommendations_df['user_id'] = specific_user_id\n",
    "user_recommendations_df['product_id'] = user_product_pairs[:, 1]\n",
    "\n",
    "# For evaluation, let's assume you have actual ratings in a DataFrame `actual_ratings_df`\n",
    "# which contains columns ['user_id', 'product_id', 'rating']\n",
    "actual_ratings_df = final_data[final_data['user_id'] == specific_user_id]\n",
    "\n",
    "# Merge predicted ratings with actual ratings\n",
    "merged_df = user_recommendations_df.merge(actual_ratings_df[['product_id', 'rating']], on='product_id', how='left')\n",
    "\n",
    "# Define a threshold for positive predictions\n",
    "threshold = 3  # Define a threshold rating\n",
    "\n",
    "# Generate binary predictions based on the threshold\n",
    "merged_df['predicted_positive'] = (merged_df['predicted_rating'] >= threshold).astype(int)\n",
    "merged_df['actual_positive'] = (merged_df['rating'] >= threshold).astype(int)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(merged_df['actual_positive'], merged_df['predicted_positive'], zero_division=0)\n",
    "recall = recall_score(merged_df['actual_positive'], merged_df['predicted_positive'], zero_division=0)\n",
    "f1 = f1_score(merged_df['actual_positive'], merged_df['predicted_positive'], zero_division=0)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287863cf-2865-4af3-ab6e-781ca67aab19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ce2900-47d3-4a23-b189-74fbaf7d2e8a",
   "metadata": {},
   "source": [
    "## COLLOBORATIVE FILTERING USING SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a133934-0179-42c7-bc38-63b26b46ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load datasets\n",
    "reviews_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/Reviews/combined_file.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0fbf32-94dc-4a04-9e13-c341e646cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ratings to numeric\n",
    "reviews_data['rating'] = pd.to_numeric(reviews_data['rating'], errors='coerce')\n",
    "reviews_data.dropna(subset=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498b4f71-7c35-4862-9341-6e9432baaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))  # Assuming rating scale is from 1 to 5\n",
    "data = Dataset.load_from_df(reviews_data[['author_id', 'product_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3a2d7e-186b-4842-af30-f2ce6dc98fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc3c5d9-2fdf-4f96-8393-baecce549a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x345ddc920>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SVD for collaborative filtering\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7cf97d6-8ce8-4e3b-8823-70855edbe74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e410d0e3-1c9c-4838-9947-68009ac46b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/product_info.csv', dtype=str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00b4963a-384c-432b-b9d7-776a789d6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get product names from product_ids\n",
    "def get_product_name(product_id):\n",
    "    product_info_row = product_info_data[product_info_data['product_id'] == product_id]\n",
    "    if not product_info_row.empty:\n",
    "        return product_info_row['product_name'].values[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c1d427-bd3d-4bad-908d-d5235fdb9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get product recommendations for a user\n",
    "def get_recommendations(user_id, model, num_recommendations=5):\n",
    "    # Get a list of all product_ids\n",
    "    all_product_ids = reviews_data['product_id'].unique()\n",
    "    \n",
    "    # Predict ratings for all products for the given user\n",
    "    user_recommendations = []\n",
    "    for product_id in all_product_ids:\n",
    "        predicted_rating = model.predict(user_id, product_id).est\n",
    "        user_recommendations.append((product_id, predicted_rating))\n",
    "    \n",
    "    # Sort by predicted rating and return the top recommendations\n",
    "    user_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get product names for the top recommendations\n",
    "    recommendations_with_names = []\n",
    "    for product_id, predicted_rating in user_recommendations[:num_recommendations]:\n",
    "        product_name = get_product_name(product_id)\n",
    "        recommendations_with_names.append((product_id, product_name, predicted_rating))\n",
    "    \n",
    "    return recommendations_with_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b12473-1e06-4370-8ff9-ceb1ff6adeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: P439055, Product Name: GENIUS Sleeping Collagen Moisturizer, Predicted Rating: 4.99\n",
      "Product ID: P471038, Product Name: Glaze Lip Oil, Predicted Rating: 4.97\n",
      "Product ID: P378852, Product Name: GinZing Ultra-Hydrating Energy-Boosting Cream, Predicted Rating: 4.96\n",
      "Product ID: P404322, Product Name: ExfoliKate Cleanser Daily Foaming Wash, Predicted Rating: 4.95\n",
      "Product ID: P379510, Product Name: Advanced Génifique Radiance Boosting Face Serum, Predicted Rating: 4.92\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_id_example = '2190293206' \n",
    "recommendations = get_recommendations(user_id_example, model)\n",
    "\n",
    "# Print each recommendation on a new line\n",
    "for product_id, product_name, predicted_rating in recommendations:\n",
    "    print(f\"Product ID: {product_id}, Product Name: {product_name}, Predicted Rating: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b0d3c-4349-4be4-871e-d3558eca563d",
   "metadata": {},
   "source": [
    "## MODEL PERFROMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7892d17a-4e04-445f-9846-b143cec4e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6332\n",
      "Precision: 0.80\n",
      "Recall: 0.73\n",
      "F1 Score: 0.74\n",
      "Accuracy (RMSE): 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate precision, accuracy, and F1 score\n",
    "def calculate_metrics(predictions):\n",
    "    # Get the true ratings and predicted ratings\n",
    "    y_true = [pred.r_ui for pred in predictions]\n",
    "    y_pred = [round(pred.est) for pred in predictions]  # Assuming ratings are in integer values\n",
    "\n",
    "    # Calculate precision, recall, and F1 score using 'macro' average for multiclass\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)  # Handle zero division\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calculate RMSE for accuracy\n",
    "    accuracy_score = accuracy.rmse(predictions)  # Already calculated RMSE\n",
    "    \n",
    "    return precision, recall, f1, accuracy_score\n",
    "\n",
    "# Calculate metrics\n",
    "precision, recall, f1, accuracy_score = calculate_metrics(predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy (RMSE): {accuracy_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929cbbd-e0e2-420d-94f6-b848dfe09377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa94d2-131c-4044-8ad8-7d367886be60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915beb6d-709a-4b6c-aae1-e7c3229156a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/nx2__31n62781txpbf95sg7m0000gn/T/ipykernel_13520/3345482632.py:11: DtypeWarning: Columns (0,4,6,7,8,9,10,11,12,13,14,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/Reviews/combined_file.csv', dtype={'author_id': str, 'product_id': str, 'rating': np.float32})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVDpp, NMF, KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Load data\n",
    "reviews_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/Reviews/combined_file.csv', dtype={'author_id': str, 'product_id': str, 'rating': np.float32})\n",
    "product_info_data = pd.read_csv('/Users/yogesh/Study/Recommender_Systems/product_info.csv', dtype={'product_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f05c4e1-1abc-4f3e-b661-a06be21a3336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (4.66.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dbc4c5-f394-42c5-a844-ce1c97a04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Reader object\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the dataset into surprise\n",
    "data = Dataset.load_from_df(reviews_data[['author_id', 'product_id', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e957dc-1cde-48a3-bdec-5371196beeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models\n",
    "base_models = [\n",
    "    ('svdpp', SVDpp()),\n",
    "    ('nmf', NMF()),\n",
    "    ('knn_baseline', KNNBaseline()),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abbd5f0-d22a-42a2-ad28-8cbb1cf4eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for the stacking model\n",
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbf2d35-f8bf-4d14-ba2e-a67bca3de3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2f0ea-bd2b-452e-b5f1-be18ed4dd96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training base models:   0%|                               | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train each base model and collect predictions\n",
    "for name, model in tqdm(base_models, desc=\"Training base models\"):\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    X_train.append([pred.est for pred in predictions])\n",
    "    y_train.append([pred.r_ui for pred in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3680b2f-3f7c-418e-8be3-17e44ee804ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
